                                                                𝐕𝐢𝐬𝐚 𝐒𝐐𝐋 𝐈𝐧𝐭𝐞𝐫𝐯𝐢𝐞𝐰 𝐐𝐮𝐞𝐬𝐭𝐢𝐨𝐧𝐬

## 📌 𝐏𝐫𝐨𝐛𝐥𝐞𝐦 𝐒𝐭𝐚𝐭𝐞𝐦𝐞𝐧𝐭

/*
𝐐𝟏:- 𝐕𝐢𝐬𝐚 𝐢𝐬 𝐚𝐧𝐚𝐥𝐲𝐬𝐢𝐧𝐠 𝐢𝐭𝐬 𝐩𝐚𝐫𝐭𝐧𝐞𝐫𝐬𝐡𝐢𝐩 𝐰𝐢𝐭𝐡 𝐀𝐩𝐩𝐥𝐲𝐏𝐚𝐲. 𝐂𝐚𝐥𝐜𝐮𝐥𝐚𝐭𝐞 𝐭𝐡𝐞 𝐭𝐨𝐭𝐚𝐥 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧
𝐯𝐨𝐥𝐮𝐦𝐞 𝐟𝐨𝐫 𝐞𝐚𝐜𝐡 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭 𝐰𝐡𝐞𝐫𝐞 𝐭𝐡𝐞 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐰𝐚𝐬 𝐩𝐞𝐫𝐟𝐨𝐫𝐦𝐞𝐝 𝐯𝐢𝐚 𝐀𝐩𝐩𝐥𝐞𝐏𝐚𝐲.

𝐎𝐮𝐭𝐩𝐮𝐭 𝐭𝐡𝐞 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭 𝐈𝐃 𝐚𝐧𝐝 𝐭𝐡𝐞 𝐭𝐨𝐭𝐚𝐥 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬. 𝐅𝐨𝐫 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭𝐬 𝐰𝐢𝐭𝐡 𝐧𝐨 𝐀𝐩𝐩𝐥𝐞𝐏𝐚𝐲 
𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬, 𝐨𝐮𝐭𝐩𝐮𝐭 𝐭𝐡𝐞𝐢𝐫 𝐭𝐨𝐭𝐚𝐥 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐯𝐨𝐥𝐮𝐦𝐞 𝐚𝐬 𝟎. 𝐃𝐢𝐬𝐩𝐥𝐚𝐲 𝐭𝐡𝐞 𝐫𝐞𝐬𝐮𝐥𝐭 𝐢𝐧
𝐝𝐞𝐬𝐜𝐞𝐧𝐝𝐢𝐧𝐠 𝐨𝐫𝐝𝐞𝐫 𝐨𝐟 𝐭𝐡𝐞 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐯𝐨𝐥𝐮𝐦𝐞.
*/

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 𝐓𝐚𝐛𝐥𝐞:- 
CREATE TABLE transactions (
    merchant_id INT,
    transaction_amount INT,
    payment_method VARCHAR(50)
);

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 𝐒𝐚𝐦𝐩𝐥𝐞 𝐃𝐚𝐭𝐚:- 
INSERT INTO transactions (merchant_id, transaction_amount, payment_method) VALUES
(1, 600, 'Contactless Chip'),
(1, 850, 'apple pay'),
(1, 500, 'Apple Pay'),
(2, 560, 'Magstripe'),
(2, 400, 'Samsung Pay'),
(4, 1200, 'apple pay');


## ✅ 𝐄𝐱𝐩𝐞𝐜𝐭𝐞𝐝 𝐎𝐮𝐭𝐩𝐮𝐭
+-------------+-------------------+
| 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭_𝐢𝐝 | 𝐭𝐨𝐭𝐚𝐥_𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬  |
+-------------+-------------------+
|      1      |        1350       |
+-------------+-------------------+
|      4      |        1200       |
+-------------+-------------------+
|      2      |         0         |
+-------------+-------------------+

---------------------------------------------------------------------------------------------------------------------------------------------------------------

## 📌 𝐏𝐫𝐨𝐛𝐥𝐞𝐦 𝐒𝐭𝐚𝐭𝐞𝐦𝐞𝐧𝐭

/*
𝐐𝟐:- 𝐒𝐚𝐲 𝐲𝐨𝐮 𝐡𝐚𝐯𝐞 𝐚𝐜𝐜𝐞𝐬𝐬 𝐭𝐨 𝐚𝐥𝐥 𝐭𝐡𝐞 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 𝐟𝐨𝐫 𝐚 𝐠𝐢𝐯𝐞𝐧 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭 𝐚𝐜𝐜𝐨𝐮𝐧𝐭. 
𝐖𝐫𝐢𝐭𝐞 𝐚 𝐪𝐮𝐞𝐫𝐲 𝐭𝐨 𝐩𝐫𝐢𝐧𝐭 𝐭𝐡𝐞 𝐜𝐮𝐦𝐮𝐥𝐚𝐭𝐢𝐯𝐞 𝐛𝐚𝐥𝐚𝐧𝐜𝐞 𝐨𝐟 𝐭𝐡𝐞 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭 𝐚𝐜𝐜𝐨𝐮𝐧𝐭 𝐚𝐭 
𝐭𝐡𝐞 𝐞𝐧𝐝 𝐨𝐟 𝐞𝐚𝐜𝐡 𝐝𝐚𝐲, 𝐰𝐢𝐭𝐡 𝐭𝐡𝐞 𝐭𝐨𝐭𝐚𝐥 𝐛𝐚𝐥𝐚𝐧𝐜𝐞 𝐫𝐞𝐬𝐞𝐭 𝐛𝐚𝐜𝐤 𝐭𝐨 𝐳𝐞𝐫𝐨 𝐚𝐭 𝐭𝐡𝐞 𝐞𝐧𝐝 
𝐨𝐟 𝐭𝐡𝐞 𝐦𝐨𝐧𝐭𝐡. 𝐎𝐮𝐭𝐩𝐮𝐭 𝐭𝐡𝐞 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐝𝐚𝐭𝐞 𝐚𝐧𝐝 𝐜𝐮𝐦𝐮𝐥𝐚𝐭𝐢𝐯𝐞 𝐛𝐚𝐥𝐚𝐧𝐜𝐞.
*/

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 𝐓𝐚𝐛𝐥𝐞:- 
CREATE TABLE transactions_ (
    transaction_id INT,
    type VARCHAR(20),
    amount DECIMAL(10, 2),
    transaction_date DATETIME
);

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 𝐒𝐚𝐦𝐩𝐥𝐞 𝐃𝐚𝐭𝐚:- 
INSERT INTO transactions_ (transaction_id, type, amount, transaction_date) VALUES
(19153, 'deposit', 65.90, '2022-07-10 10:00:00'),
(53151, 'deposit', 178.55, '2022-07-08 10:00:00'),
(29776, 'withdrawal', 25.90, '2022-07-08 10:00:00'),
(16461, 'withdrawal', 45.99, '2022-07-08 10:00:00'),
(77134, 'deposit', 32.60, '2022-07-10 10:00:00');

## ✅ 𝐄𝐱𝐩𝐞𝐜𝐭𝐞𝐝 𝐎𝐮𝐭𝐩𝐮𝐭
+---------------------+---------+
|  𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧_𝐝𝐚𝐭𝐞    | 𝐛𝐚𝐥𝐚𝐧𝐜𝐞  |
+---------------------+---------+
| 07/08/2022 12:00:00 | 106.66  |
| 07/10/2022 12:00:00 | 205.16  |
+---------------------+---------+

--------------------------------------------------------------------------------------------------------------------------------------------------------------

## 📌 𝐏𝐫𝐨𝐛𝐥𝐞𝐦 𝐒𝐭𝐚𝐭𝐞𝐦𝐞𝐧𝐭

/*
𝐐𝟑:- 𝐕𝐢𝐬𝐚 𝐈𝐧𝐜. 𝐢𝐬 𝐚𝐧 𝐀𝐦𝐞𝐫𝐢𝐜𝐚𝐧 𝐦𝐮𝐥𝐭𝐢𝐧𝐚𝐭𝐢𝐨𝐧𝐚𝐥 𝐟𝐢𝐧𝐚𝐧𝐜𝐢𝐚𝐥 𝐬𝐞𝐫𝐯𝐢𝐜𝐞𝐬 𝐜𝐨𝐫𝐩𝐨𝐫𝐚𝐭𝐢𝐨𝐧 
𝐭𝐡𝐚𝐭 𝐟𝐚𝐜𝐢𝐥𝐢𝐭𝐚𝐭𝐞𝐬 𝐞𝐥𝐞𝐜𝐭𝐫𝐨𝐧𝐢𝐜 𝐟𝐮𝐧𝐝𝐬 𝐭𝐫𝐚𝐧𝐬𝐟𝐞𝐫𝐬 𝐭𝐡𝐫𝐨𝐮𝐠𝐡𝐨𝐮𝐭 𝐭𝐡𝐞 𝐰𝐨𝐫𝐥𝐝, 
𝐦𝐨𝐬𝐭 𝐜𝐨𝐦𝐦𝐨𝐧𝐥𝐲 𝐭𝐡𝐫𝐨𝐮𝐠𝐡 𝐕𝐢𝐬𝐚-𝐛𝐫𝐚𝐧𝐝𝐞𝐝 𝐜𝐫𝐞𝐝𝐢𝐭 𝐜𝐚𝐫𝐝𝐬, 𝐝𝐞𝐛𝐢𝐭 𝐜𝐚𝐫𝐝𝐬 𝐚𝐧𝐝 𝐩𝐫𝐞𝐩𝐚𝐢𝐝 𝐜𝐚𝐫𝐝𝐬.

𝐈𝐧 𝐭𝐡𝐢𝐬 𝐒𝐐𝐋 𝐢𝐧𝐭𝐞𝐫𝐯𝐢𝐞𝐰 𝐪𝐮𝐞𝐬𝐭𝐢𝐨𝐧, 𝐲𝐨𝐮𝐫 𝐭𝐚𝐬𝐤 𝐢𝐬 𝐭𝐨 𝐰𝐫𝐢𝐭𝐞
𝐚 𝐒𝐐𝐋 𝐪𝐮𝐞𝐫𝐲 𝐭𝐡𝐚𝐭 𝐜𝐚𝐥𝐜𝐮𝐥𝐚𝐭𝐞𝐬 𝐭𝐡𝐞 𝐭𝐨𝐭𝐚𝐥 𝐧𝐮𝐦𝐛𝐞𝐫 𝐨𝐟 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 𝐚𝐧𝐝
𝐚𝐯𝐞𝐫𝐚𝐠𝐞 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐚𝐦𝐨𝐮𝐧𝐭 𝐞𝐚𝐜𝐡 𝐦𝐨𝐧𝐭𝐡 𝐟𝐨𝐫 𝐞𝐚𝐜𝐡 𝐜𝐨𝐮𝐧𝐭𝐫𝐲, 𝐚𝐧𝐝 𝐫𝐚𝐧𝐤 
𝐭𝐡𝐞𝐦 𝐰𝐢𝐭𝐡𝐢𝐧 𝐞𝐚𝐜𝐡 𝐜𝐨𝐮𝐧𝐭𝐫𝐲 𝐛𝐚𝐬𝐞𝐝 𝐨𝐧 𝐭𝐡𝐞 𝐭𝐨𝐭𝐚𝐥 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐜𝐨𝐮𝐧𝐭.
*/

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬_𝐝𝐚𝐭𝐚:- 
CREATE TABLE transactions_data (
    transaction_id INT PRIMARY KEY,
    transaction_date DATE,
    card_id VARCHAR(10),
    country VARCHAR(50),
    amount DECIMAL(10, 2)
);

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬_𝐝𝐚𝐭𝐚:-
INSERT INTO transactions_data (transaction_id, transaction_date, card_id, country, amount) VALUES
(101, '2022-06-08', '001', 'USA', 200),
(102, '2022-06-10', '002', 'USA', 300),
(103, '2022-06-18', '003', 'Canada', 150),
(104, '2022-07-26', '004', 'UK', 250),
(105, '2022-07-05', '005', 'USA', 350);

## ✅ 𝐄𝐱𝐩𝐞𝐜𝐭𝐞𝐝 𝐎𝐮𝐭𝐩𝐮𝐭
+-------+---------+-------------------+-------------+------+
| 𝐦𝐨𝐧𝐭𝐡 | 𝐜𝐨𝐮𝐧𝐭𝐫𝐲 | 𝐭𝐨𝐭𝐚𝐥_𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 | 𝐚𝐯𝐠_𝐚𝐦𝐨𝐮𝐧𝐭 | 𝐫𝐚𝐧𝐤   |
+-------+---------+-------------------+-------------+------+
|   6   | Canada  |         1          |   150.000000 |   1  |
|   7   | UK      |         1          |   250.000000 |   1  |
|   6   | USA     |         2          |   250.000000 |   1  |
|   7   | USA     |         1          |   350.000000 |   2  |
+-------+---------+-------------------+-------------+------+


---------------------------------------------------------------------------------------------------------------------------------------------------------------

## 📌 𝐏𝐫𝐨𝐛𝐥𝐞𝐦 𝐒𝐭𝐚𝐭𝐞𝐦𝐞𝐧𝐭

/*
𝐐𝟒:- 𝐫𝐞𝐭𝐫𝐢𝐞𝐯𝐞 𝐚𝐥𝐥 𝐜𝐚𝐫𝐝𝐡𝐨𝐥𝐝𝐞𝐫𝐬 𝐰𝐡𝐨 𝐡𝐚𝐯𝐞 𝐦𝐚𝐝𝐞 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬 𝐰𝐢𝐭𝐡 𝐭𝐡𝐞 𝐭𝐨𝐭𝐚𝐥 
𝐚𝐦𝐨𝐮𝐧𝐭 𝐨𝐯𝐞𝐫 $𝟐𝟎𝟎 𝐢𝐧 𝐭𝐡𝐞𝐢𝐫 𝐨𝐰𝐧 𝐜𝐨𝐮𝐧𝐭𝐫𝐲'𝐬 𝐬𝐭𝐨𝐫𝐞𝐬 𝐢𝐧 𝐉𝐮𝐥𝐲 𝟐𝟎𝟐𝟐,
*/


-- 𝐂𝐫𝐞𝐚𝐭𝐞 𝐜𝐚𝐫𝐝𝐡𝐨𝐥𝐝𝐞𝐫 𝐭𝐚𝐛𝐥𝐞
CREATE TABLE cardholder (
    cardholder_id INT PRIMARY KEY,
    name VARCHAR(100),
    country VARCHAR(50)
);

-- 𝐈𝐧𝐬𝐞𝐫𝐭 𝐯𝐚𝐥𝐮𝐞𝐬 𝐢𝐧𝐭𝐨 𝐜𝐚𝐫𝐝𝐡𝐨𝐥𝐝𝐞𝐫
INSERT INTO cardholder (cardholder_id, name, country) VALUES
(101, 'John Doe', 'USA'),
(202, 'Alice Johnson', 'USA'),
(303, 'Bob Williams', 'CAN');

-- 𝐂𝐫𝐞𝐚𝐭𝐞 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭 𝐭𝐚𝐛𝐥𝐞
CREATE TABLE merchant (
    merchant_id VARCHAR(10) PRIMARY KEY,
    name VARCHAR(100),
    city VARCHAR(50),
    country VARCHAR(50)
);

-- 𝐈𝐧𝐬𝐞𝐫𝐭 𝐯𝐚𝐥𝐮𝐞𝐬 𝐢𝐧𝐭𝐨 𝐦𝐞𝐫𝐜𝐡𝐚𝐧𝐭
INSERT INTO merchant (merchant_id, name, city, country) VALUES
('M001', 'Best Buy', 'New York', 'USA'),
('M002', 'Apple Store', 'San Francisco', 'USA'),
('M003', 'Tim Hortons', 'Toronto', 'CAN');

-- 𝐂𝐫𝐞𝐚𝐭𝐞 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐭𝐚𝐛𝐥𝐞
CREATE TABLE transaction_details (
    transaction_id VARCHAR(10) PRIMARY KEY,
    amount DECIMAL(10, 2),
    transaction_date DATETIME,
    card_id INT,
    merchant_id VARCHAR(10),
    FOREIGN KEY (card_id) REFERENCES cardholder(cardholder_id),
    FOREIGN KEY (merchant_id) REFERENCES merchant(merchant_id)
);

-- 𝐈𝐧𝐬𝐞𝐫𝐭 𝐯𝐚𝐥𝐮𝐞𝐬 𝐢𝐧𝐭𝐨 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧 𝐭𝐚𝐛𝐥𝐞
INSERT INTO transaction_details (transaction_id, amount, transaction_date, card_id, merchant_id) VALUES
('T001', 350, '2022-06-08 00:00:00', 101, 'M001'),
('T002', 200, '2022-06-10 00:00:00', 101, 'M002'),
('T003', 450, '2022-06-18 00:00:00', 202, 'M003'),
('T004', 600, '2022-07-26 00:00:00', 303, 'M001'),
('T005', 400, '2022-07-05 00:00:00', 101, 'M001');

## ✅ 𝐄𝐱𝐩𝐞𝐜𝐭𝐞𝐝 𝐎𝐮𝐭𝐩𝐮𝐭
+---------------+----------+--------------+------------------+
|  𝐜𝐚𝐫𝐝𝐡𝐨𝐥𝐝𝐞𝐫_𝐢𝐝 | 𝐧𝐚𝐦𝐞     | 𝐭𝐨𝐭𝐚𝐥_𝐚𝐦𝐨𝐮𝐧𝐭 | 𝐭𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧_𝐜𝐨𝐮𝐧𝐭 |
+---------------+----------+--------------+------------------+
| 101           | John Doe | 400.00       | 1                |
+---------------+----------+--------------+------------------+

---------------------------------------------------------------------------------------------------------------------------------------------------------------

## 📌 𝐏𝐫𝐨𝐛𝐥𝐞𝐦 𝐒𝐭𝐚𝐭𝐞𝐦𝐞𝐧𝐭

/*
𝐐𝟓:- 𝐈𝐝𝐞𝐧𝐭𝐢𝐟𝐲 𝐭𝐡𝐞 𝐭𝐨𝐩 𝟑 𝐚𝐫𝐞𝐚𝐬 𝐰𝐢𝐭𝐡 𝐭𝐡𝐞 𝐡𝐢𝐠𝐡𝐞𝐬𝐭 𝐜𝐮𝐬𝐭𝐨𝐦𝐞𝐫 𝐝𝐞𝐧𝐬𝐢𝐭𝐲. 𝐂𝐮𝐬𝐭𝐨𝐦𝐞𝐫 𝐝𝐞𝐧𝐬𝐢𝐭𝐲 = (𝐭𝐨𝐭𝐚𝐥 𝐧𝐮𝐦𝐛𝐞𝐫 𝐨𝐟 𝐮𝐧𝐢𝐪𝐮𝐞 𝐜𝐮𝐬𝐭𝐨𝐦𝐞𝐫𝐬 𝐢𝐧 𝐭𝐡𝐞 𝐚𝐫𝐞𝐚 / 𝐚𝐫𝐞𝐚 𝐬𝐢𝐳𝐞).
𝐘𝐨𝐮𝐫 𝐨𝐮𝐭𝐩𝐮𝐭 𝐬𝐡𝐨𝐮𝐥𝐝 𝐢𝐧𝐜𝐥𝐮𝐝𝐞 𝐭𝐡𝐞 𝐚𝐫𝐞𝐚 𝐧𝐚𝐦𝐞 𝐚𝐧𝐝 𝐢𝐭𝐬 𝐜𝐚𝐥𝐜𝐮𝐥𝐚𝐭𝐞𝐝 𝐜𝐮𝐬𝐭𝐨𝐦𝐞𝐫 𝐝𝐞𝐧𝐬𝐢𝐭𝐲.
*/

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬_𝐫𝐞𝐜𝐨𝐫𝐝𝐬 𝐓𝐚𝐛𝐥𝐞:- 
CREATE TABLE transaction_records (
customer_id BIGINT, 
store_id BIGINT,
transaction_amount BIGINT,
transaction_date DATETIME,
transaction_id BIGINT PRIMARY KEY);

-- 𝐓𝐫𝐚𝐧𝐬𝐚𝐜𝐭𝐢𝐨𝐧𝐬_𝐫𝐞𝐜𝐨𝐫𝐝𝐬 𝐒𝐚𝐦𝐩𝐥𝐞 𝐃𝐚𝐭𝐚:- 
INSERT INTO transaction_records (customer_id, store_id, transaction_amount, transaction_date, transaction_id) 
VALUES (101, 1, 500, '2024-01-01 10:15:00', 10001), (102, 2, 1500, '2024-01-02 12:30:00', 10002), 
(103, 1, 700, '2024-01-03 14:00:00', 10003), (104, 3, 1200, '2024-01-04 09:45:00', 10004),
(105, 2, 800, '2024-01-05 11:20:00', 10005);


-- 𝐒𝐭𝐨𝐫𝐞𝐬 𝐓𝐚𝐛𝐥𝐞:- 
CREATE TABLE stores (
area_name VARCHAR(20), 
area_size BIGINT,
store_id BIGINT PRIMARY KEY,
store_location TEXT, 
store_open_date DATETIME);

-- 𝐒𝐭𝐨𝐫𝐞𝐬 𝐒𝐚𝐦𝐩𝐥𝐞 𝐃𝐚𝐭𝐚:- 
INSERT INTO stores (area_name, area_size, store_id, store_location, store_open_date)
VALUES ('Downtown', 1000, 1, 'Main Street', '2020-01-01'), ('Uptown', 1500, 2, 'Park Avenue', '2021-06-15'),
('Midtown', 1200, 3, 'Broadway', '2019-11-20'), ('Suburbs', 2000, 4, 'Elm Street', '2018-08-10');


## ✅ 𝐄𝐱𝐩𝐞𝐜𝐭𝐞𝐝 𝐎𝐮𝐭𝐩𝐮𝐭

+-----------+---------------------+
| 𝐚𝐫𝐞𝐚_𝐧𝐚𝐦𝐞 | 𝐜𝐮𝐬𝐭_𝐝𝐞𝐧            |
+-----------+---------------------+
| Downtown  | 0.0020000000000000  |
| Uptown    | 0.0013333333333333  |
| Midtown   | 0.0008333333333333  |
+-----------+---------------------+

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------










